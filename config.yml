llm:
  model: gpt-4o-mini
  temperature: 0.5

fast_llm:
  model: gpt-4o
  temperature: 0

long_context_llm:
  model: gpt-4.1
  temperature: 0

embedding_model: text-embedding-3-large


token_max: 1000